{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 移除最后conv最后一层网络\n",
    "\n",
    "把 resnet最后一层再拼接回去，重新开始训练 ，finetune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loader import *\n",
    "from model import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set high parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "extract_size = 2048\n",
    "class_size = 61\n",
    "\n",
    "\n",
    "# 图片格式转化\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "#     transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_vaild = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load encoded datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding 4981/4982->99.98%, spent_time:7:51.123.00"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# exract the images to embedding tensor\n",
    "# remove the last conv layer\n",
    "encoder = EncoderClearCut()\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "fileFold = './bottle_neck/resnet152_train_clear_remove_last_conv'\n",
    "data_loader = get_encoder_loader_fold(transform_train, encoder, device, fileFold, load=False, mode='train', batch_size=batch_size)\n",
    "\n",
    "validFileFold = './bottle_neck/resnet152_valid_clear_remove_last_conv'\n",
    "valid_data_loader = get_encoder_loader_fold(transform_vaild, encoder, device, validFileFold, load=False, mode='valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the classify network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvClassify(nn.Module):\n",
    "    \"\"\"Get the last conv layer of resnet to train\"\"\"\n",
    "    def __init__(self, in_features, class_size):\n",
    "        super(ConvClassify, self).__init__()\n",
    "        self.drop = nn.Dropout2d(0.4)\n",
    "        self.conv = nn.Conv2d(1024, 2048, 3, stride=2)\n",
    "        self.pool = nn.AvgPool2d(6)\n",
    "        self.bn = nn.BatchNorm1d(2048)\n",
    "        self.fc = nn.Linear(in_features, class_size)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        y = self.drop(features)\n",
    "        y = self.conv(y)\n",
    "        y = self.pool(y)\n",
    "        y = y.view(y.size(0), -1)\n",
    "        y = self.bn(y)\n",
    "        y = self.fc(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_class_acc(classify_model, valid_data_loader):\n",
    "    classify_model = classify_model.eval()\n",
    "    predict = []\n",
    "    total = len(valid_data_loader.dataset)\n",
    "    for idx in range(total):\n",
    "        embed, _ = valid_data_loader.dataset[idx]\n",
    "        p = classify_model(embed).argmax().item()\n",
    "        predict.append(p)\n",
    "        print('\\r %d / %d' % (idx, total), end='')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    df_refer = valid_data_loader.dataset.refer\n",
    "    df_refer[\"predict\"] = predict\n",
    "    df_refer['correct'] = df_refer.predict == df_refer.disease_class\n",
    "    accuracy = (df_refer.correct == True).sum()/len(df_refer)\n",
    "    return accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拼接resnet 最后一个 conv layer，用来训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the total number of training steps per epoch\n",
    "total_step = int(len(data_loader.dataset)/batch_size)\n",
    "\n",
    "classify_model = ConvClassify(extract_size, class_size)\n",
    "classify_model = classify_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# with RMSprop to slow the desent gradient progress\n",
    "optimizer = torch.optim.Adam(classify_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best trained model,yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_model.load_state_dict(torch.load('./models/class_train_last_conv_layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(classify_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4981 / 4982, Step [126/127], Loss: 0.9728, Accuracy: 64.45%, Best_acc: 69.92%            \n",
      " Epoch 6, spent time:319.92s, valid: 69.93%\n",
      " 4981 / 4982, Step [126/127], Loss: 1.0193, Accuracy: 67.19%, Best_acc: 73.05%            \n",
      " Epoch 7, spent time:326.24s, valid: 70.75%\n",
      " 4981 / 4982, Step [126/127], Loss: 0.7152, Accuracy: 72.66%, Best_acc: 73.83%            \n",
      " Epoch 8, spent time:309.71s, valid: 71.44%\n",
      " 4981 / 4982, Step [126/127], Loss: 0.8822, Accuracy: 69.92%, Best_acc: 76.17%            \n",
      " Epoch 9, spent time:320.46s, valid: 72.48%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.8656, Accuracy: 71.48%, Best_acc: 76.17%            \n",
      " Epoch 10, spent time:309.17s, valid: 71.56%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.9334, Accuracy: 67.97%, Best_acc: 76.17%            \n",
      " Epoch 11, spent time:317.99s, valid: 72.72%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.8210, Accuracy: 72.27%, Best_acc: 76.56%            \n",
      " Epoch 12, spent time:363.16s, valid: 72.58%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.7148, Accuracy: 72.27%, Best_acc: 79.30%            \n",
      " Epoch 13, spent time:327.91s, valid: 71.84%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.8074, Accuracy: 69.92%, Best_acc: 79.30%            \n",
      " Epoch 14, spent time:308.74s, valid: 72.48%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.7321, Accuracy: 74.22%, Best_acc: 79.30%            \n",
      " Epoch 15, spent time:305.74s, valid: 72.52%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.8293, Accuracy: 67.19%, Best_acc: 79.30%            \n",
      " Epoch 16, spent time:319.55s, valid: 72.74%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.7626, Accuracy: 67.97%, Best_acc: 79.30%            \n",
      " Epoch 17, spent time:291.87s, valid: 73.30%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.7512, Accuracy: 73.05%, Best_acc: 79.30%            \n",
      " Epoch 18, spent time:278.38s, valid: 71.92%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.6272, Accuracy: 76.17%, Best_acc: 80.47%            \n",
      " Epoch 19, spent time:280.60s, valid: 72.58%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.7466, Accuracy: 75.00%, Best_acc: 80.47%            \n",
      " Epoch 20, spent time:291.00s, valid: 72.14%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.7059, Accuracy: 76.95%, Best_acc: 82.42%            \n",
      " Epoch 21, spent time:292.58s, valid: 72.66%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.7159, Accuracy: 74.22%, Best_acc: 82.42%            \n",
      " Epoch 22, spent time:281.81s, valid: 72.74%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.6567, Accuracy: 73.83%, Best_acc: 82.42%            \n",
      " Epoch 23, spent time:267.68s, valid: 73.32%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.7397, Accuracy: 73.44%, Best_acc: 83.98%            \n",
      " Epoch 24, spent time:277.07s, valid: 72.20%\n",
      " 4981 / 4982], Step [126/127], Loss: 0.5798, Accuracy: 79.30%, Best_acc: 83.98%            \n",
      " Epoch 25, spent time:276.31s, valid: 71.72%\n",
      "Epoch [26/50], Step [2/127], Loss: 0.7150, Accuracy: 74.61%, Best_acc: 83.98%            "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "\n",
    "for epoch in range(6, num_epochs+6):\n",
    "    classify_model = classify_model.train()\n",
    "    start = time.time()\n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        # Ramdomly get samples\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        \n",
    "        embeds, targets = next(iter(data_loader))\n",
    "        \n",
    "        embeds = embeds.squeeze(1)\n",
    "        targets = targets.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        classify_model.zero_grad()\n",
    "        \n",
    "        outputs = classify_model(embeds)\n",
    "        \n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i_step%2 == 0:\n",
    "            # calculate the status\n",
    "            predict_result = outputs.argmax(1)\n",
    "            accuracy = torch.sum(predict_result == targets).item() / batch_size * 100\n",
    "            best_acc = accuracy if accuracy > best_acc else best_acc\n",
    "            stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Accuracy: %.2f%%, Best_acc: %.2f%%\\\n",
    "            ' % (epoch, num_epochs, i_step, total_step, loss.item(), accuracy, best_acc)\n",
    "            print('\\r' + stats, end='')\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    valid_acc = valid_class_acc(classify_model, valid_data_loader)\n",
    "    print('\\n Epoch {}, spent time:{:.2f}s, valid: {:.2f}%'.format(epoch, time.time()-start, valid_acc))       \n",
    "    if epoch%5 == 0:\n",
    "        torch.save(classify_model.state_dict(), os.path.join('./models', 'class_train_last_conv_layer_%d.pkl' % epoch))\n",
    "# torch.save(classify_model.state_dict(), os.path.join('./models', 'class_train_last_conv_layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./bottle_neck/resnet152_valid_clear_remove_last_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileFold = './bottle_neck/resnet152_valid_clear_remove_last_conv'\n",
    "valid_data_loader = get_encoder_loader_fold(transform_vaild, encoder, device, fileFold, load=True, mode='valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_model.load_state_dict(torch.load('./models/class_train_last_conv_layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The final accuracy is %.2f' % valid_class_acc(classify_model, valid_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With 100 epoch the result is the best,yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./models/class_multify_rm1layer_100.pkl ./models/class_multify_rm1layer_good.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
