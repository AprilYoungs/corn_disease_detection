{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 移除最后conv最后一层网络\n",
    "\n",
    "    用resnet18提取特征, 使用两个個fc进行分类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loader import *\n",
    "from model import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderResnet18Cut(nn.Module):\n",
    "    \"\"\"remove the last conv network\"\"\"\n",
    "    def __init__(self):\n",
    "        super(EncoderResnet18Cut, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "        modules = list(resnet.children())[:-3]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.pool = nn.AvgPool2d(14)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.resnet(images)\n",
    "        features = self.pool(features)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiFCClassify(nn.Module):\n",
    "    def __init__(self, in_features, class_size):\n",
    "        super(MultiFCClassify, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(in_features)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(in_features, class_size)\n",
    "    \n",
    "    def forward(self, features):\n",
    "#         y = self.fc1(features)\n",
    "        y = self.bn(features)\n",
    "        y = self.drop(features)\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_class_acc(classify_model, valid_data_loader):\n",
    "    classify_model = classify_model.eval()\n",
    "    \n",
    "    indices = valid_data_loader.dataset.get_train_indices()\n",
    "    new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "    valid_data_loader.batch_sampler.sampler = new_sampler\n",
    "    \n",
    "    embeds, targets = next(iter(valid_data_loader))\n",
    "    \n",
    "    embeds = embeds.squeeze(1)\n",
    "    targets = targets.type(torch.LongTensor).to(device)\n",
    "        \n",
    "    outputs = classify_model(embeds)\n",
    "    \n",
    "    predict_result = outputs.argmax(1)\n",
    "    size = len(predict_result)\n",
    "    accuracy = torch.sum(predict_result == targets).item() / size * 100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set high parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "extract_size = 256\n",
    "class_size = 61\n",
    "\n",
    "\n",
    "# 图片格式转化\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "#     transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_vaild = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load encoded datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# exract the images to embedding tensor\n",
    "# remove the last conv layer\n",
    "encoder = EncoderResnet18Cut()\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "train_fold = './bottle_neck/resnet18_train_remove_last_conv'\n",
    "data_loader = get_encoder_loader_fold(transform_train, encoder, device, train_fold, load=False, mode='train', batch_size=batch_size)\n",
    "\n",
    "\n",
    "valid_flod = './bottle_neck/resnet18_valid_remove_last_conv'\n",
    "valid_data_loader = get_encoder_loader_fold(transform_train, encoder, device, valid_flod, load=False, mode='valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用两层网络,结果过拟合,训练准确率很高,验证结果比较差,使用再试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the total number of training steps per epoch\n",
    "total_step = int(len(data_loader.dataset)/batch_size)\n",
    "\n",
    "classify_model = MultiFCClassify(extract_size, class_size)\n",
    "classify_model = classify_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# with RMSprop to slow the desent gradient progress\n",
    "optimizer = torch.optim.Adam(classify_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best trained model,yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_model.load_state_dict(torch.load('./models/class_single_resnet18rm1layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(classify_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [120/127], Loss: 3.7266, Accuracy: 8.20%, Best_acc: 8.20%            \n",
      " Epoch 1, spent time:10.55s, valid: 7.81%\n",
      "Epoch [2/100], Step [120/127], Loss: 3.8126, Accuracy: 6.64%, Best_acc: 9.38%            \n",
      " Epoch 2, spent time:10.51s, valid: 8.98%\n",
      "Epoch [3/100], Step [120/127], Loss: 3.7799, Accuracy: 6.64%, Best_acc: 9.38%            \n",
      " Epoch 3, spent time:10.45s, valid: 4.69%\n",
      "Epoch [4/100], Step [120/127], Loss: 3.7600, Accuracy: 10.55%, Best_acc: 10.55%            \n",
      " Epoch 4, spent time:10.59s, valid: 8.59%\n",
      "Epoch [5/100], Step [120/127], Loss: 3.7637, Accuracy: 4.69%, Best_acc: 11.33%             \n",
      " Epoch 5, spent time:10.67s, valid: 6.64%\n",
      "Epoch [6/100], Step [120/127], Loss: 3.8311, Accuracy: 5.86%, Best_acc: 11.33%            \n",
      " Epoch 6, spent time:10.51s, valid: 5.47%\n",
      "Epoch [7/100], Step [120/127], Loss: 3.7612, Accuracy: 7.42%, Best_acc: 11.33%            \n",
      " Epoch 7, spent time:10.51s, valid: 10.94%\n",
      "Epoch [8/100], Step [120/127], Loss: 3.7010, Accuracy: 13.28%, Best_acc: 13.28%            \n",
      " Epoch 8, spent time:10.55s, valid: 7.42%\n",
      "Epoch [9/100], Step [120/127], Loss: 3.7739, Accuracy: 10.55%, Best_acc: 13.28%            \n",
      " Epoch 9, spent time:10.54s, valid: 7.03%\n",
      "Epoch [10/100], Step [120/127], Loss: 3.8048, Accuracy: 8.59%, Best_acc: 13.28%            \n",
      " Epoch 10, spent time:10.66s, valid: 12.89%\n",
      "Epoch [11/100], Step [120/127], Loss: 3.7018, Accuracy: 12.50%, Best_acc: 13.28%            \n",
      " Epoch 11, spent time:10.79s, valid: 9.38%\n",
      "Epoch [12/100], Step [120/127], Loss: 3.7836, Accuracy: 8.20%, Best_acc: 13.28%            \n",
      " Epoch 12, spent time:10.52s, valid: 5.86%\n",
      "Epoch [13/100], Step [120/127], Loss: 3.6428, Accuracy: 11.33%, Best_acc: 13.28%            \n",
      " Epoch 13, spent time:10.57s, valid: 7.03%\n",
      "Epoch [14/100], Step [120/127], Loss: 3.8005, Accuracy: 8.59%, Best_acc: 13.28%            \n",
      " Epoch 14, spent time:10.53s, valid: 8.98%\n",
      "Epoch [15/100], Step [120/127], Loss: 3.7109, Accuracy: 7.42%, Best_acc: 13.28%            \n",
      " Epoch 15, spent time:10.56s, valid: 11.72%\n",
      "Epoch [16/100], Step [120/127], Loss: 3.6717, Accuracy: 11.33%, Best_acc: 13.28%            \n",
      " Epoch 16, spent time:10.46s, valid: 8.20%\n",
      "Epoch [17/100], Step [120/127], Loss: 3.7726, Accuracy: 7.03%, Best_acc: 13.28%             \n",
      " Epoch 17, spent time:10.59s, valid: 10.55%\n",
      "Epoch [18/100], Step [120/127], Loss: 3.6901, Accuracy: 9.77%, Best_acc: 13.28%             \n",
      " Epoch 18, spent time:10.53s, valid: 10.94%\n",
      "Epoch [19/100], Step [120/127], Loss: 3.6846, Accuracy: 9.77%, Best_acc: 13.28%            \n",
      " Epoch 19, spent time:10.28s, valid: 14.45%\n",
      "Epoch [20/100], Step [120/127], Loss: 3.6827, Accuracy: 11.72%, Best_acc: 13.28%            \n",
      " Epoch 20, spent time:10.56s, valid: 8.59%\n",
      "Epoch [21/100], Step [120/127], Loss: 3.6852, Accuracy: 10.55%, Best_acc: 13.28%            \n",
      " Epoch 21, spent time:10.64s, valid: 6.25%\n",
      "Epoch [22/100], Step [120/127], Loss: 3.7629, Accuracy: 8.59%, Best_acc: 13.28%             \n",
      " Epoch 22, spent time:10.53s, valid: 12.50%\n",
      "Epoch [23/100], Step [120/127], Loss: 3.6530, Accuracy: 11.72%, Best_acc: 13.28%            \n",
      " Epoch 23, spent time:10.50s, valid: 15.23%\n",
      "Epoch [24/100], Step [120/127], Loss: 3.7197, Accuracy: 8.98%, Best_acc: 13.28%             \n",
      " Epoch 24, spent time:10.63s, valid: 12.89%\n",
      "Epoch [25/100], Step [120/127], Loss: 3.5922, Accuracy: 10.16%, Best_acc: 13.28%            \n",
      " Epoch 25, spent time:10.61s, valid: 12.50%\n",
      "Epoch [26/100], Step [120/127], Loss: 3.6516, Accuracy: 9.38%, Best_acc: 13.28%             \n",
      " Epoch 26, spent time:10.53s, valid: 12.50%\n",
      "Epoch [27/100], Step [120/127], Loss: 3.7292, Accuracy: 8.98%, Best_acc: 13.28%             \n",
      " Epoch 27, spent time:10.55s, valid: 11.33%\n",
      "Epoch [28/100], Step [120/127], Loss: 3.6218, Accuracy: 9.38%, Best_acc: 13.67%             \n",
      " Epoch 28, spent time:10.55s, valid: 7.81%\n",
      "Epoch [29/100], Step [120/127], Loss: 3.5163, Accuracy: 14.06%, Best_acc: 14.06%            \n",
      " Epoch 29, spent time:10.59s, valid: 10.55%\n",
      "Epoch [30/100], Step [120/127], Loss: 3.5868, Accuracy: 11.33%, Best_acc: 15.23%            \n",
      " Epoch 30, spent time:10.77s, valid: 8.59%\n",
      "Epoch [31/100], Step [120/127], Loss: 3.6297, Accuracy: 9.38%, Best_acc: 15.23%             \n",
      " Epoch 31, spent time:10.54s, valid: 11.72%\n",
      "Epoch [32/100], Step [120/127], Loss: 3.6528, Accuracy: 8.59%, Best_acc: 15.23%             \n",
      " Epoch 32, spent time:10.62s, valid: 14.06%\n",
      "Epoch [33/100], Step [120/127], Loss: 3.6833, Accuracy: 10.55%, Best_acc: 15.23%            \n",
      " Epoch 33, spent time:10.54s, valid: 10.16%\n",
      "Epoch [34/100], Step [120/127], Loss: 3.7265, Accuracy: 8.20%, Best_acc: 15.23%             \n",
      " Epoch 34, spent time:10.53s, valid: 9.77%\n",
      "Epoch [35/100], Step [120/127], Loss: 3.7719, Accuracy: 7.42%, Best_acc: 15.23%             \n",
      " Epoch 35, spent time:10.54s, valid: 11.33%\n",
      "Epoch [36/100], Step [120/127], Loss: 3.6226, Accuracy: 11.72%, Best_acc: 15.23%            \n",
      " Epoch 36, spent time:10.58s, valid: 11.72%\n",
      "Epoch [37/100], Step [120/127], Loss: 3.6848, Accuracy: 8.20%, Best_acc: 15.23%             \n",
      " Epoch 37, spent time:10.55s, valid: 10.55%\n",
      "Epoch [38/100], Step [120/127], Loss: 3.5991, Accuracy: 8.98%, Best_acc: 15.23%             \n",
      " Epoch 38, spent time:10.55s, valid: 12.11%\n",
      "Epoch [39/100], Step [120/127], Loss: 3.6252, Accuracy: 10.16%, Best_acc: 15.23%            \n",
      " Epoch 39, spent time:10.59s, valid: 11.72%\n",
      "Epoch [40/100], Step [120/127], Loss: 3.6439, Accuracy: 12.89%, Best_acc: 16.41%            \n",
      " Epoch 40, spent time:10.51s, valid: 17.19%\n",
      "Epoch [41/100], Step [120/127], Loss: 3.4764, Accuracy: 14.84%, Best_acc: 16.41%            \n",
      " Epoch 41, spent time:10.43s, valid: 8.20%\n",
      "Epoch [42/100], Step [120/127], Loss: 3.5700, Accuracy: 11.33%, Best_acc: 16.41%            \n",
      " Epoch 42, spent time:10.63s, valid: 7.42%\n",
      "Epoch [43/100], Step [120/127], Loss: 3.6558, Accuracy: 11.72%, Best_acc: 16.41%            \n",
      " Epoch 43, spent time:10.58s, valid: 12.11%\n",
      "Epoch [44/100], Step [120/127], Loss: 3.5111, Accuracy: 13.28%, Best_acc: 16.41%            \n",
      " Epoch 44, spent time:10.50s, valid: 9.38%\n",
      "Epoch [45/100], Step [120/127], Loss: 3.5339, Accuracy: 11.72%, Best_acc: 16.41%            \n",
      " Epoch 45, spent time:10.60s, valid: 12.50%\n",
      "Epoch [46/100], Step [120/127], Loss: 3.5862, Accuracy: 13.67%, Best_acc: 16.41%            \n",
      " Epoch 46, spent time:10.46s, valid: 10.16%\n",
      "Epoch [47/100], Step [120/127], Loss: 3.5571, Accuracy: 13.28%, Best_acc: 16.41%            \n",
      " Epoch 47, spent time:10.54s, valid: 12.50%\n",
      "Epoch [48/100], Step [120/127], Loss: 3.5905, Accuracy: 12.50%, Best_acc: 16.80%            \n",
      " Epoch 48, spent time:10.35s, valid: 17.97%\n",
      "Epoch [49/100], Step [120/127], Loss: 3.6055, Accuracy: 10.94%, Best_acc: 16.80%            \n",
      " Epoch 49, spent time:10.37s, valid: 14.45%\n",
      "Epoch [50/100], Step [120/127], Loss: 3.6217, Accuracy: 10.94%, Best_acc: 16.80%            \n",
      " Epoch 50, spent time:10.55s, valid: 11.72%\n",
      "Epoch [51/100], Step [120/127], Loss: 3.4879, Accuracy: 12.11%, Best_acc: 16.80%            \n",
      " Epoch 51, spent time:10.60s, valid: 14.06%\n",
      "Epoch [52/100], Step [120/127], Loss: 3.5796, Accuracy: 11.72%, Best_acc: 16.80%            \n",
      " Epoch 52, spent time:10.58s, valid: 12.50%\n",
      "Epoch [53/100], Step [120/127], Loss: 3.4847, Accuracy: 12.50%, Best_acc: 16.80%            \n",
      " Epoch 53, spent time:10.65s, valid: 16.02%\n",
      "Epoch [54/100], Step [120/127], Loss: 3.5901, Accuracy: 12.11%, Best_acc: 16.80%            \n",
      " Epoch 54, spent time:10.40s, valid: 15.23%\n",
      "Epoch [55/100], Step [120/127], Loss: 3.5940, Accuracy: 10.94%, Best_acc: 16.80%            \n",
      " Epoch 55, spent time:10.59s, valid: 12.89%\n",
      "Epoch [56/100], Step [120/127], Loss: 3.5485, Accuracy: 12.11%, Best_acc: 16.80%            \n",
      " Epoch 56, spent time:10.46s, valid: 12.89%\n",
      "Epoch [57/100], Step [120/127], Loss: 3.5147, Accuracy: 12.89%, Best_acc: 16.80%            \n",
      " Epoch 57, spent time:10.56s, valid: 11.33%\n",
      "Epoch [58/100], Step [120/127], Loss: 3.5717, Accuracy: 12.11%, Best_acc: 16.80%            \n",
      " Epoch 58, spent time:10.47s, valid: 12.11%\n",
      "Epoch [59/100], Step [120/127], Loss: 3.4956, Accuracy: 11.33%, Best_acc: 16.80%            \n",
      " Epoch 59, spent time:10.53s, valid: 12.50%\n",
      "Epoch [60/100], Step [120/127], Loss: 3.4397, Accuracy: 13.67%, Best_acc: 16.80%            \n",
      " Epoch 60, spent time:10.60s, valid: 14.84%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Step [120/127], Loss: 3.6068, Accuracy: 9.38%, Best_acc: 16.80%             \n",
      " Epoch 61, spent time:10.49s, valid: 14.45%\n",
      "Epoch [62/100], Step [120/127], Loss: 3.5722, Accuracy: 9.77%, Best_acc: 16.80%             \n",
      " Epoch 62, spent time:10.59s, valid: 15.23%\n",
      "Epoch [63/100], Step [120/127], Loss: 3.6412, Accuracy: 10.55%, Best_acc: 16.80%            \n",
      " Epoch 63, spent time:10.54s, valid: 13.28%\n",
      "Epoch [64/100], Step [120/127], Loss: 3.5602, Accuracy: 14.84%, Best_acc: 16.80%            \n",
      " Epoch 64, spent time:10.54s, valid: 15.23%\n",
      "Epoch [65/100], Step [120/127], Loss: 3.5618, Accuracy: 10.16%, Best_acc: 16.80%            \n",
      " Epoch 65, spent time:10.52s, valid: 15.62%\n",
      "Epoch [66/100], Step [120/127], Loss: 3.5189, Accuracy: 10.55%, Best_acc: 16.80%            \n",
      " Epoch 66, spent time:10.74s, valid: 16.02%\n",
      "Epoch [67/100], Step [120/127], Loss: 3.6140, Accuracy: 8.59%, Best_acc: 16.80%             \n",
      " Epoch 67, spent time:10.61s, valid: 12.89%\n",
      "Epoch [68/100], Step [120/127], Loss: 3.4057, Accuracy: 14.45%, Best_acc: 17.97%            \n",
      " Epoch 68, spent time:10.56s, valid: 15.23%\n",
      "Epoch [69/100], Step [120/127], Loss: 3.4231, Accuracy: 17.97%, Best_acc: 17.97%            \n",
      " Epoch 69, spent time:10.57s, valid: 16.02%\n",
      "Epoch [70/100], Step [120/127], Loss: 3.5263, Accuracy: 10.55%, Best_acc: 17.97%            \n",
      " Epoch 70, spent time:10.67s, valid: 17.19%\n",
      "Epoch [71/100], Step [120/127], Loss: 3.4187, Accuracy: 16.41%, Best_acc: 17.97%            \n",
      " Epoch 71, spent time:10.46s, valid: 16.80%\n",
      "Epoch [72/100], Step [120/127], Loss: 3.5501, Accuracy: 12.11%, Best_acc: 17.97%            \n",
      " Epoch 72, spent time:10.64s, valid: 11.33%\n",
      "Epoch [73/100], Step [120/127], Loss: 3.5039, Accuracy: 12.50%, Best_acc: 17.97%            \n",
      " Epoch 73, spent time:10.59s, valid: 12.50%\n",
      "Epoch [74/100], Step [120/127], Loss: 3.4680, Accuracy: 10.94%, Best_acc: 17.97%            \n",
      " Epoch 74, spent time:10.55s, valid: 14.45%\n",
      "Epoch [75/100], Step [120/127], Loss: 3.4410, Accuracy: 16.41%, Best_acc: 17.97%            \n",
      " Epoch 75, spent time:10.52s, valid: 19.14%\n",
      "Epoch [76/100], Step [120/127], Loss: 3.4974, Accuracy: 15.23%, Best_acc: 17.97%            \n",
      " Epoch 76, spent time:10.51s, valid: 16.02%\n",
      "Epoch [77/100], Step [120/127], Loss: 3.5361, Accuracy: 12.50%, Best_acc: 17.97%            \n",
      " Epoch 77, spent time:10.47s, valid: 14.84%\n",
      "Epoch [78/100], Step [120/127], Loss: 3.4849, Accuracy: 14.06%, Best_acc: 17.97%            \n",
      " Epoch 78, spent time:10.38s, valid: 17.19%\n",
      "Epoch [79/100], Step [120/127], Loss: 3.4266, Accuracy: 15.62%, Best_acc: 17.97%            \n",
      " Epoch 79, spent time:10.48s, valid: 18.36%\n",
      "Epoch [80/100], Step [120/127], Loss: 3.5217, Accuracy: 12.11%, Best_acc: 17.97%            \n",
      " Epoch 80, spent time:10.67s, valid: 14.45%\n",
      "Epoch [81/100], Step [120/127], Loss: 3.5248, Accuracy: 12.50%, Best_acc: 17.97%            \n",
      " Epoch 81, spent time:10.60s, valid: 16.41%\n",
      "Epoch [82/100], Step [120/127], Loss: 3.3991, Accuracy: 14.45%, Best_acc: 17.97%            \n",
      " Epoch 82, spent time:10.55s, valid: 14.84%\n",
      "Epoch [83/100], Step [120/127], Loss: 3.4734, Accuracy: 14.45%, Best_acc: 17.97%            \n",
      " Epoch 83, spent time:10.55s, valid: 17.97%\n",
      "Epoch [84/100], Step [120/127], Loss: 3.4636, Accuracy: 12.11%, Best_acc: 17.97%            \n",
      " Epoch 84, spent time:10.60s, valid: 17.58%\n",
      "Epoch [85/100], Step [120/127], Loss: 3.4855, Accuracy: 15.23%, Best_acc: 17.97%            \n",
      " Epoch 85, spent time:10.48s, valid: 16.02%\n",
      "Epoch [86/100], Step [120/127], Loss: 3.2985, Accuracy: 18.36%, Best_acc: 18.36%            \n",
      " Epoch 86, spent time:10.52s, valid: 10.55%\n",
      "Epoch [87/100], Step [120/127], Loss: 3.4012, Accuracy: 17.19%, Best_acc: 18.36%            \n",
      " Epoch 87, spent time:10.62s, valid: 14.84%\n",
      "Epoch [88/100], Step [120/127], Loss: 3.4440, Accuracy: 12.89%, Best_acc: 18.36%            "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3d3177959f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/corn_disease_detection/data_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disease_class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start = time.time()\n",
    "    classify_model = classify_model.train()\n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        # Ramdomly get samples\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        embeds, targets = next(iter(data_loader))\n",
    "        \n",
    "        embeds = embeds.squeeze(1)\n",
    "        targets = targets.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        classify_model.zero_grad()\n",
    "        \n",
    "        outputs = classify_model(embeds)\n",
    "        \n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i_step%20 == 0:\n",
    "            # calculate the status\n",
    "            predict_result = outputs.argmax(1)\n",
    "            accuracy = torch.sum(predict_result == targets).item() / batch_size * 100\n",
    "            best_acc = accuracy if accuracy > best_acc else best_acc\n",
    "            \n",
    "            stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Accuracy: %.2f%%, Best_acc: %.2f%%\\\n",
    "            ' % (epoch, num_epochs, i_step, total_step, loss.item(), accuracy, best_acc)\n",
    "            print('\\r' + stats, end='')\n",
    "            sys.stdout.flush()\n",
    "    valid_acc = valid_class_acc(classify_model, valid_data_loader)\n",
    "    print('\\n Epoch {}, spent time:{:.2f}s, valid: {:.2f}%'.format(epoch, time.time()-start, valid_acc))       \n",
    "    if epoch%10 == 0:\n",
    "        torch.save(classify_model.state_dict(), os.path.join('./models', 'class_single_resnet18rm1layer_%d.pkl' % epoch))\n",
    "torch.save(classify_model.state_dict(), os.path.join('./models', 'class_single_resnet18rm1layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_flod = './bottle_neck/resnet18_valid_remove_last_conv'\n",
    "valid_data_loader = get_encoder_loader_fold(transform_train, encoder, device, valid_flod, load=False, mode='valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_model.load_state_dict(torch.load('./models/class_single_resnet18rm1layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy is 69.43%.\n"
     ]
    }
   ],
   "source": [
    "classify_model = classify_model.eval()\n",
    "predict = []\n",
    "total = len(valid_data_loader.dataset)\n",
    "for idx in range(total):\n",
    "    embed, target = valid_data_loader.dataset[idx]\n",
    "    p = classify_model(embed).argmax().item()\n",
    "    predict.append(p == target)\n",
    "    \n",
    "accuracy = sum(predict)/len(predict)\n",
    "print('The final accuracy is %.2f%%.' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why? Why the random validation accuracy is good, but not the whole dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With 100 epoch the result is the best,yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./models/class_multify_rm1layer_100.pkl ./models/class_multify_rm1layer_good.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
