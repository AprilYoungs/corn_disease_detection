{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用desnet201提取特征\n",
    "\n",
    "训练效果很差,在10%徘徊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loader import *\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDensenet201(nn.Module):\n",
    "    \"\"\"remove the last conv network\"\"\"\n",
    "    def __init__(self):\n",
    "        super(EncoderDensenet201, self).__init__()\n",
    "        densenet = models.densenet201(pretrained=True)\n",
    "        for param in densenet.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "        modules = list(densenet.children())[:-1]\n",
    "        self.densenet = nn.Sequential(*modules)\n",
    "        self.pool = nn.AvgPool2d(7)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.densenet(images)\n",
    "        features = self.pool(features)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoader = get_loader(transform_train)\n",
    "image = testLoader.dataset[0][0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1920])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = EncoderDensenet201()\n",
    "encoder(image).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiFCClassify(nn.Module):\n",
    "    def __init__(self, in_features, class_size):\n",
    "        super(MultiFCClassify, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, in_features//3)\n",
    "#         self.bn = nn.BatchNorm1d(in_features//3)\n",
    "#         self.drop = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(in_features//3, class_size)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        y = self.fc1(features)\n",
    "#         y = self.bn(y)\n",
    "#         y = self.drop(y)\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_class_acc(classify_model, valid_data_loader, device):\n",
    "    classify_model = classify_model.eval()\n",
    "    \n",
    "    indices = valid_data_loader.dataset.get_train_indices()\n",
    "    new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "    valid_data_loader.batch_sampler.sampler = new_sampler\n",
    "    \n",
    "    embeds, targets = next(iter(valid_data_loader))\n",
    "    \n",
    "    embeds = embeds.squeeze(1)\n",
    "    targets = targets.type(torch.LongTensor).to(device)\n",
    "        \n",
    "    outputs = classify_model(embeds)\n",
    "    \n",
    "    predict_result = outputs.argmax(1)\n",
    "    size = len(predict_result)\n",
    "    accuracy = torch.sum(predict_result == targets).item() / size * 100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set high parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "extract_size = 1920\n",
    "class_size = 61\n",
    "\n",
    "\n",
    "# 图片格式转化\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "#     transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_vaild = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load encoded datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "encoding 4981/4982->99.98%, spent_time:6:38.34"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# exract the images to embedding tensor\n",
    "# remove the last conv layer\n",
    "encoder = EncoderDensenet201()\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# train_fold = './bottle_neck/densenet201_train'\n",
    "# data_loader = get_encoder_loader_fold(transform_train, encoder, device, train_fold, load=True, mode='train', batch_size=batch_size)\n",
    "\n",
    "print(\"\\n\")\n",
    "valid_flod = './bottle_neck/densenet201_valid'\n",
    "valid_data_loader = get_encoder_loader_fold(transform_vaild, encoder, device, valid_flod, load=True, mode='valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用两层网络,结果过拟合,训练准确率很高,验证结果比较差,使用再试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = valid_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the total number of training steps per epoch\n",
    "total_step = int(len(data_loader.dataset)/batch_size)\n",
    "\n",
    "classify_model = MultiFCClassify(extract_size, class_size)\n",
    "classify_model = classify_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# with RMSprop to slow the desent gradient progress\n",
    "optimizer = torch.optim.Adam(classify_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best trained model,yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify_model.load_state_dict(torch.load('./models/class_single_resnet18rm1layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(classify_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1, spent time:1.81s, valid: 7.42%\n",
      "\n",
      " Epoch 2, spent time:1.77s, valid: 6.64%\n",
      "\n",
      " Epoch 3, spent time:1.78s, valid: 10.55%\n",
      "\n",
      " Epoch 4, spent time:1.74s, valid: 8.20%\n",
      "\n",
      " Epoch 5, spent time:1.74s, valid: 8.98%\n",
      "\n",
      " Epoch 6, spent time:1.72s, valid: 7.81%\n",
      "\n",
      " Epoch 7, spent time:1.72s, valid: 9.38%\n",
      "\n",
      " Epoch 8, spent time:1.70s, valid: 5.86%\n",
      "\n",
      " Epoch 9, spent time:1.72s, valid: 8.98%\n",
      "\n",
      " Epoch 10, spent time:1.72s, valid: 7.03%\n",
      "\n",
      " Epoch 11, spent time:1.72s, valid: 5.08%\n",
      "\n",
      " Epoch 12, spent time:1.73s, valid: 3.52%\n",
      "\n",
      " Epoch 13, spent time:1.75s, valid: 7.81%\n",
      "\n",
      " Epoch 14, spent time:1.74s, valid: 5.47%\n",
      "\n",
      " Epoch 15, spent time:1.80s, valid: 8.20%\n",
      "\n",
      " Epoch 16, spent time:1.75s, valid: 3.91%\n",
      "\n",
      " Epoch 17, spent time:1.71s, valid: 4.69%\n",
      "\n",
      " Epoch 18, spent time:1.72s, valid: 7.03%\n",
      "\n",
      " Epoch 19, spent time:1.76s, valid: 3.52%\n",
      "\n",
      " Epoch 20, spent time:1.74s, valid: 7.03%\n",
      "\n",
      " Epoch 21, spent time:1.74s, valid: 8.98%\n",
      "\n",
      " Epoch 22, spent time:1.73s, valid: 5.86%\n",
      "\n",
      " Epoch 23, spent time:1.72s, valid: 5.47%\n",
      "\n",
      " Epoch 24, spent time:1.71s, valid: 7.03%\n",
      "\n",
      " Epoch 25, spent time:1.72s, valid: 4.30%\n",
      "\n",
      " Epoch 26, spent time:1.73s, valid: 7.03%\n",
      "\n",
      " Epoch 27, spent time:1.72s, valid: 7.42%\n",
      "\n",
      " Epoch 28, spent time:1.78s, valid: 7.42%\n",
      "\n",
      " Epoch 29, spent time:1.71s, valid: 8.98%\n",
      "\n",
      " Epoch 30, spent time:1.73s, valid: 8.98%\n",
      "\n",
      " Epoch 31, spent time:1.74s, valid: 7.42%\n",
      "\n",
      " Epoch 32, spent time:1.76s, valid: 8.98%\n",
      "\n",
      " Epoch 33, spent time:1.69s, valid: 5.86%\n",
      "\n",
      " Epoch 34, spent time:1.70s, valid: 5.86%\n",
      "\n",
      " Epoch 35, spent time:1.71s, valid: 11.33%\n",
      "\n",
      " Epoch 36, spent time:1.74s, valid: 8.20%\n",
      "\n",
      " Epoch 37, spent time:1.78s, valid: 6.25%\n",
      "\n",
      " Epoch 38, spent time:1.72s, valid: 5.86%\n",
      "\n",
      " Epoch 39, spent time:1.72s, valid: 6.25%\n",
      "\n",
      " Epoch 40, spent time:1.73s, valid: 5.86%\n",
      "\n",
      " Epoch 41, spent time:1.76s, valid: 6.64%\n",
      "\n",
      " Epoch 42, spent time:1.77s, valid: 8.20%\n",
      "\n",
      " Epoch 43, spent time:1.73s, valid: 6.64%\n",
      "\n",
      " Epoch 44, spent time:1.71s, valid: 6.64%\n",
      "\n",
      " Epoch 45, spent time:1.75s, valid: 7.42%\n",
      "\n",
      " Epoch 46, spent time:1.78s, valid: 5.47%\n",
      "\n",
      " Epoch 47, spent time:1.75s, valid: 6.64%\n",
      "\n",
      " Epoch 48, spent time:1.77s, valid: 6.25%\n",
      "\n",
      " Epoch 49, spent time:1.76s, valid: 8.98%\n",
      "\n",
      " Epoch 50, spent time:1.75s, valid: 6.64%\n",
      "\n",
      " Epoch 51, spent time:1.77s, valid: 8.59%\n",
      "\n",
      " Epoch 52, spent time:1.73s, valid: 5.86%\n",
      "\n",
      " Epoch 53, spent time:1.71s, valid: 7.42%\n",
      "\n",
      " Epoch 54, spent time:1.70s, valid: 7.03%\n",
      "\n",
      " Epoch 55, spent time:1.69s, valid: 7.81%\n",
      "\n",
      " Epoch 56, spent time:1.71s, valid: 7.81%\n",
      "\n",
      " Epoch 57, spent time:1.71s, valid: 6.64%\n",
      "\n",
      " Epoch 58, spent time:1.70s, valid: 5.86%\n",
      "\n",
      " Epoch 59, spent time:1.75s, valid: 10.55%\n",
      "\n",
      " Epoch 60, spent time:1.76s, valid: 6.25%\n",
      "\n",
      " Epoch 61, spent time:1.83s, valid: 7.81%\n",
      "\n",
      " Epoch 62, spent time:1.75s, valid: 8.59%\n",
      "\n",
      " Epoch 63, spent time:1.71s, valid: 7.03%\n",
      "\n",
      " Epoch 64, spent time:1.71s, valid: 4.69%\n",
      "\n",
      " Epoch 65, spent time:1.72s, valid: 7.03%\n",
      "\n",
      " Epoch 66, spent time:1.74s, valid: 5.86%\n",
      "\n",
      " Epoch 67, spent time:1.79s, valid: 5.47%\n",
      "\n",
      " Epoch 68, spent time:1.78s, valid: 4.30%\n",
      "\n",
      " Epoch 69, spent time:1.75s, valid: 7.03%\n",
      "\n",
      " Epoch 70, spent time:1.75s, valid: 4.30%\n",
      "\n",
      " Epoch 71, spent time:1.75s, valid: 7.81%\n",
      "\n",
      " Epoch 72, spent time:1.73s, valid: 10.55%\n",
      "\n",
      " Epoch 73, spent time:1.77s, valid: 5.86%\n",
      "\n",
      " Epoch 74, spent time:1.76s, valid: 7.81%\n",
      "\n",
      " Epoch 75, spent time:1.79s, valid: 5.86%\n",
      "\n",
      " Epoch 76, spent time:1.78s, valid: 5.08%\n",
      "\n",
      " Epoch 77, spent time:1.78s, valid: 8.59%\n",
      "\n",
      " Epoch 78, spent time:1.71s, valid: 5.86%\n",
      "\n",
      " Epoch 79, spent time:1.77s, valid: 9.77%\n",
      "\n",
      " Epoch 80, spent time:1.73s, valid: 5.86%\n",
      "\n",
      " Epoch 81, spent time:1.76s, valid: 7.03%\n",
      "\n",
      " Epoch 82, spent time:1.76s, valid: 8.59%\n",
      "\n",
      " Epoch 83, spent time:1.76s, valid: 6.25%\n",
      "\n",
      " Epoch 84, spent time:1.75s, valid: 9.38%\n",
      "\n",
      " Epoch 85, spent time:1.75s, valid: 5.47%\n",
      "\n",
      " Epoch 86, spent time:1.72s, valid: 7.03%\n",
      "\n",
      " Epoch 87, spent time:1.75s, valid: 7.03%\n",
      "\n",
      " Epoch 88, spent time:1.72s, valid: 7.03%\n",
      "\n",
      " Epoch 89, spent time:1.80s, valid: 4.30%\n",
      "\n",
      " Epoch 90, spent time:1.78s, valid: 7.03%\n",
      "\n",
      " Epoch 91, spent time:1.77s, valid: 3.91%\n",
      "\n",
      " Epoch 92, spent time:1.80s, valid: 3.91%\n",
      "\n",
      " Epoch 93, spent time:1.72s, valid: 6.25%\n",
      "\n",
      " Epoch 94, spent time:1.74s, valid: 6.64%\n",
      "\n",
      " Epoch 95, spent time:1.74s, valid: 6.64%\n",
      "\n",
      " Epoch 96, spent time:1.74s, valid: 7.03%\n",
      "\n",
      " Epoch 97, spent time:1.75s, valid: 7.81%\n",
      "\n",
      " Epoch 98, spent time:1.76s, valid: 6.25%\n",
      "\n",
      " Epoch 99, spent time:1.84s, valid: 5.08%\n",
      "\n",
      " Epoch 100, spent time:1.72s, valid: 5.47%\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start = time.time()\n",
    "    classify_model = classify_model.train()\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        # Ramdomly get samples\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        embeds, targets = next(iter(data_loader))\n",
    "        \n",
    "        embeds = embeds.squeeze(1)\n",
    "        targets = targets.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        classify_model.zero_grad()\n",
    "        \n",
    "        outputs = classify_model(embeds)\n",
    "        \n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i_step%20 == 0:\n",
    "            # calculate the status\n",
    "            predict_result = outputs.argmax(1)\n",
    "            accuracy = torch.sum(predict_result == targets).item() / batch_size * 100\n",
    "            best_acc = accuracy if accuracy > best_acc else best_acc\n",
    "            \n",
    "            stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Accuracy: %.2f%%, Best_acc: %.2f%%\\\n",
    "            ' % (epoch, num_epochs, i_step, total_step, loss.item(), accuracy, best_acc)\n",
    "            print('\\r' + stats, end='')\n",
    "            sys.stdout.flush()\n",
    "    valid_acc = valid_class_acc(classify_model, valid_data_loader, device)\n",
    "    print('\\n Epoch {}, spent time:{:.2f}s, valid: {:.2f}%'.format(epoch, time.time()-start, valid_acc))       \n",
    "    if epoch%10 == 0:\n",
    "        torch.save(classify_model.state_dict(), os.path.join('./models', 'class_single_densenet121_%d.pkl' % epoch))\n",
    "torch.save(classify_model.state_dict(), os.path.join('./models', 'class_single_densenet121_last.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_model.load_state_dict(torch.load('./models/class_single_densenet121_last.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy is 69.43%.\n"
     ]
    }
   ],
   "source": [
    "classify_model = classify_model.eval()\n",
    "predict = []\n",
    "total = len(valid_data_loader.dataset)\n",
    "for idx in range(total):\n",
    "    embed, target = valid_data_loader.dataset[idx]\n",
    "    p = classify_model(embed).argmax().item()\n",
    "    predict.append(p == target)\n",
    "    \n",
    "accuracy = sum(predict)/len(predict)\n",
    "print('The final accuracy is %.2f%%.' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why? Why the random validation accuracy is good, but not the whole dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With 100 epoch the result is the best,yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./models/class_multify_rm1layer_100.pkl ./models/class_multify_rm1layer_good.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
