{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 移除最后conv最后一层网络\n",
    "\n",
    "使用兩個fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_loader import get_loader\n",
    "from data_loader import get_encoder_loader\n",
    "from model import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_class_acc(classify_model, valid_data_loader):\n",
    "    classify_model = classify_model.eval()\n",
    "    predict = []\n",
    "    total = len(valid_data_loader.dataset)\n",
    "    for idx in range(total):\n",
    "        embed, _ = valid_data_loader.dataset[idx]\n",
    "        p = classify_model(embed).argmax().item()\n",
    "        predict.append(p)\n",
    "        print('\\r %d / %d' % (idx, total), end='')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    df_refer = valid_data_loader.dataset.refer\n",
    "    df_refer[\"predict\"] = predict\n",
    "    df_refer['correct'] = df_refer.predict == df_refer.disease_class\n",
    "    accuracy = (df_refer.correct == True).sum()/len(df_refer)\n",
    "    return accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set high parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 300\n",
    "extract_size = 1024\n",
    "class_size = 61\n",
    "\n",
    "\n",
    "# 图片格式转化\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "#     transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_vaild = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load encoded datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# exract the images to embedding tensor\n",
    "# remove the last conv layer\n",
    "encoder = EncoderCut()\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# data_loader = get_encoder_loader(transform_train, encoder, device, mode='train', batch_size=batch_size)\n",
    "# data_loader.dataset.save_to(\"./bottle_neck/resnet152_train_remove_last_conv.h\")\n",
    "data_loader = get_encoder_loader(transform_train, encoder, device, mode='train', batch_size=batch_size, file='./bottle_neck/resnet152_train_remove_last_conv.h')\n",
    "\n",
    "# valid_data_loader = get_encoder_loader(transform_vaild, encoder, device, mode='valid', batch_size=batch_size)\n",
    "# valid_data_loader.dataset.save_to(\"./bottle_neck/resnet152_valid_rm1layer.h\")\n",
    "valid_data_loader = get_encoder_loader(transform_vaild, encoder, device, mode='valid', batch_size=batch_size, file=\"./bottle_neck/resnet152_valid_rm1layer.h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用两层网络,结果过拟合,训练准确率很高,验证结果比较差,使用再试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the total number of training steps per epoch\n",
    "total_step = int(len(data_loader.dataset)/batch_size)\n",
    "\n",
    "classify_model = MultiClassify(extract_size, class_size)\n",
    "classify_model = classify_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# with RMSprop to slow the desent gradient progress\n",
    "optimizer = torch.optim.Adam(classify_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best trained model,yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_model.load_state_dict(torch.load('./models/class_multify_rm1layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(classify_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [120/127], Loss: 1.5641, Accuracy: 54.69%, Best_acc: 56.25%            \n",
      " 4981 / 4982\n",
      " Epoch 1, spent time:14.55s, valid: 55.16%\n",
      "Epoch [2/300], Step [120/127], Loss: 1.1984, Accuracy: 68.75%, Best_acc: 68.75%            \n",
      " 4981 / 4982\n",
      " Epoch 2, spent time:14.45s, valid: 58.13%\n",
      "Epoch [3/300], Step [120/127], Loss: 1.0833, Accuracy: 65.23%, Best_acc: 68.75%            \n",
      " 4981 / 4982\n",
      " Epoch 3, spent time:14.38s, valid: 61.90%\n",
      "Epoch [4/300], Step [120/127], Loss: 0.9942, Accuracy: 67.58%, Best_acc: 73.44%            \n",
      " 4981 / 4982\n",
      " Epoch 4, spent time:14.39s, valid: 64.73%\n",
      "Epoch [5/300], Step [120/127], Loss: 0.9118, Accuracy: 69.92%, Best_acc: 75.00%            \n",
      " 4981 / 4982\n",
      " Epoch 5, spent time:14.62s, valid: 66.72%\n",
      "Epoch [6/300], Step [120/127], Loss: 0.8006, Accuracy: 73.83%, Best_acc: 75.39%            \n",
      " 4981 / 4982\n",
      " Epoch 6, spent time:14.31s, valid: 67.24%\n",
      "Epoch [7/300], Step [120/127], Loss: 0.8505, Accuracy: 73.83%, Best_acc: 75.39%            \n",
      " 4981 / 4982\n",
      " Epoch 7, spent time:14.40s, valid: 69.73%\n",
      "Epoch [8/300], Step [120/127], Loss: 0.7038, Accuracy: 74.61%, Best_acc: 79.30%            \n",
      " 4981 / 4982\n",
      " Epoch 8, spent time:14.42s, valid: 69.79%\n",
      "Epoch [9/300], Step [120/127], Loss: 0.7508, Accuracy: 76.17%, Best_acc: 79.30%            \n",
      " 4981 / 4982\n",
      " Epoch 9, spent time:14.34s, valid: 71.12%\n",
      "Epoch [10/300], Step [120/127], Loss: 0.7163, Accuracy: 75.00%, Best_acc: 80.47%            \n",
      " 4981 / 4982\n",
      " Epoch 10, spent time:14.28s, valid: 70.92%\n",
      "Epoch [11/300], Step [120/127], Loss: 0.5685, Accuracy: 79.69%, Best_acc: 80.47%            \n",
      " 4981 / 4982\n",
      " Epoch 11, spent time:14.45s, valid: 70.96%\n",
      "Epoch [12/300], Step [120/127], Loss: 0.6824, Accuracy: 76.17%, Best_acc: 80.47%            \n",
      " 4981 / 4982\n",
      " Epoch 12, spent time:14.40s, valid: 73.00%\n",
      "Epoch [13/300], Step [120/127], Loss: 0.6153, Accuracy: 77.34%, Best_acc: 80.47%            \n",
      " 4981 / 4982\n",
      " Epoch 13, spent time:14.34s, valid: 72.52%\n",
      "Epoch [14/300], Step [120/127], Loss: 0.6240, Accuracy: 75.00%, Best_acc: 83.98%            \n",
      " 4981 / 4982\n",
      " Epoch 14, spent time:14.21s, valid: 72.62%\n",
      "Epoch [15/300], Step [120/127], Loss: 0.6015, Accuracy: 78.52%, Best_acc: 83.98%            \n",
      " 4981 / 4982\n",
      " Epoch 15, spent time:14.30s, valid: 72.72%\n",
      "Epoch [16/300], Step [120/127], Loss: 0.6286, Accuracy: 76.95%, Best_acc: 83.98%            \n",
      " 4981 / 4982\n",
      " Epoch 16, spent time:14.29s, valid: 73.24%\n",
      "Epoch [17/300], Step [120/127], Loss: 0.4318, Accuracy: 86.72%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 17, spent time:14.24s, valid: 73.95%\n",
      "Epoch [18/300], Step [120/127], Loss: 0.5497, Accuracy: 80.47%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 18, spent time:14.33s, valid: 74.03%\n",
      "Epoch [19/300], Step [120/127], Loss: 0.4867, Accuracy: 79.69%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 19, spent time:14.52s, valid: 73.42%\n",
      "Epoch [20/300], Step [120/127], Loss: 0.5431, Accuracy: 78.91%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 20, spent time:14.37s, valid: 73.83%\n",
      "Epoch [21/300], Step [120/127], Loss: 0.6504, Accuracy: 73.05%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 21, spent time:14.37s, valid: 73.71%\n",
      "Epoch [22/300], Step [120/127], Loss: 0.4870, Accuracy: 78.91%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 22, spent time:14.43s, valid: 74.87%\n",
      "Epoch [23/300], Step [120/127], Loss: 0.5635, Accuracy: 76.17%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 23, spent time:14.29s, valid: 73.93%\n",
      "Epoch [24/300], Step [120/127], Loss: 0.4938, Accuracy: 81.25%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 24, spent time:14.38s, valid: 74.91%\n",
      "Epoch [25/300], Step [120/127], Loss: 0.4905, Accuracy: 81.25%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 25, spent time:14.40s, valid: 75.21%\n",
      "Epoch [26/300], Step [120/127], Loss: 0.4206, Accuracy: 83.98%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 26, spent time:14.64s, valid: 74.49%\n",
      "Epoch [27/300], Step [120/127], Loss: 0.4651, Accuracy: 82.03%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 27, spent time:14.29s, valid: 75.35%\n",
      "Epoch [28/300], Step [120/127], Loss: 0.5469, Accuracy: 79.30%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 28, spent time:14.43s, valid: 74.35%\n",
      "Epoch [29/300], Step [120/127], Loss: 0.4125, Accuracy: 83.98%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 29, spent time:14.46s, valid: 74.45%\n",
      "Epoch [30/300], Step [120/127], Loss: 0.5011, Accuracy: 81.25%, Best_acc: 86.72%            \n",
      " 4981 / 4982\n",
      " Epoch 30, spent time:14.38s, valid: 74.03%\n",
      "Epoch [31/300], Step [120/127], Loss: 0.4605, Accuracy: 83.20%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 31, spent time:14.28s, valid: 76.64%\n",
      "Epoch [32/300], Step [120/127], Loss: 0.5014, Accuracy: 79.69%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 32, spent time:14.46s, valid: 75.61%\n",
      "Epoch [33/300], Step [120/127], Loss: 0.5161, Accuracy: 80.86%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 33, spent time:14.32s, valid: 75.53%\n",
      "Epoch [34/300], Step [120/127], Loss: 0.4675, Accuracy: 79.69%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 34, spent time:14.32s, valid: 76.33%\n",
      "Epoch [35/300], Step [120/127], Loss: 0.4066, Accuracy: 85.55%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 35, spent time:14.25s, valid: 76.50%\n",
      "Epoch [36/300], Step [120/127], Loss: 0.4151, Accuracy: 86.33%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 36, spent time:14.31s, valid: 75.43%\n",
      "Epoch [37/300], Step [120/127], Loss: 0.3862, Accuracy: 84.38%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 37, spent time:14.32s, valid: 76.27%\n",
      "Epoch [38/300], Step [120/127], Loss: 0.4784, Accuracy: 80.86%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 38, spent time:14.37s, valid: 75.51%\n",
      "Epoch [39/300], Step [120/127], Loss: 0.4622, Accuracy: 81.25%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 39, spent time:14.44s, valid: 76.74%\n",
      "Epoch [40/300], Step [120/127], Loss: 0.3703, Accuracy: 83.20%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 40, spent time:14.37s, valid: 75.33%\n",
      "Epoch [41/300], Step [120/127], Loss: 0.3589, Accuracy: 85.16%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 41, spent time:14.23s, valid: 76.64%\n",
      "Epoch [42/300], Step [120/127], Loss: 0.4487, Accuracy: 83.20%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 42, spent time:14.41s, valid: 74.79%\n",
      "Epoch [43/300], Step [120/127], Loss: 0.4242, Accuracy: 84.38%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 43, spent time:14.29s, valid: 76.56%\n",
      "Epoch [44/300], Step [120/127], Loss: 0.3515, Accuracy: 84.77%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 44, spent time:14.25s, valid: 74.73%\n",
      "Epoch [45/300], Step [120/127], Loss: 0.4371, Accuracy: 82.81%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 45, spent time:14.29s, valid: 76.58%\n",
      "Epoch [46/300], Step [120/127], Loss: 0.4075, Accuracy: 82.03%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 46, spent time:14.32s, valid: 76.37%\n",
      "Epoch [47/300], Step [120/127], Loss: 0.4392, Accuracy: 82.42%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 47, spent time:14.33s, valid: 76.78%\n",
      "Epoch [48/300], Step [120/127], Loss: 0.4486, Accuracy: 79.30%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 48, spent time:14.58s, valid: 76.68%\n",
      "Epoch [49/300], Step [120/127], Loss: 0.4911, Accuracy: 81.25%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 49, spent time:14.37s, valid: 76.86%\n",
      "Epoch [50/300], Step [120/127], Loss: 0.3397, Accuracy: 84.38%, Best_acc: 87.50%            \n",
      " 4981 / 4982\n",
      " Epoch 50, spent time:14.30s, valid: 75.87%\n",
      "Epoch [51/300], Step [120/127], Loss: 0.3906, Accuracy: 83.59%, Best_acc: 87.89%            \n",
      " 4981 / 4982\n",
      " Epoch 51, spent time:14.39s, valid: 76.56%\n",
      "Epoch [52/300], Step [120/127], Loss: 0.3644, Accuracy: 84.38%, Best_acc: 87.89%            \n",
      " 4981 / 4982\n",
      " Epoch 52, spent time:14.37s, valid: 76.27%\n",
      "Epoch [53/300], Step [120/127], Loss: 0.3258, Accuracy: 88.67%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 53, spent time:14.38s, valid: 76.25%\n",
      "Epoch [54/300], Step [120/127], Loss: 0.4095, Accuracy: 82.81%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 54, spent time:14.41s, valid: 76.27%\n",
      "Epoch [55/300], Step [120/127], Loss: 0.3572, Accuracy: 87.50%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 55, spent time:14.34s, valid: 77.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/300], Step [120/127], Loss: 0.5099, Accuracy: 78.91%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 56, spent time:14.22s, valid: 75.81%\n",
      "Epoch [57/300], Step [120/127], Loss: 0.3424, Accuracy: 85.55%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 57, spent time:14.32s, valid: 76.13%\n",
      "Epoch [58/300], Step [120/127], Loss: 0.2973, Accuracy: 88.67%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 58, spent time:14.41s, valid: 77.12%\n",
      "Epoch [59/300], Step [120/127], Loss: 0.2863, Accuracy: 87.11%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 59, spent time:14.39s, valid: 76.78%\n",
      "Epoch [60/300], Step [120/127], Loss: 0.3693, Accuracy: 82.81%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 60, spent time:14.34s, valid: 77.86%\n",
      "Epoch [61/300], Step [120/127], Loss: 0.3409, Accuracy: 83.20%, Best_acc: 88.67%            \n",
      " 4981 / 4982\n",
      " Epoch 61, spent time:14.35s, valid: 76.52%\n",
      "Epoch [62/300], Step [120/127], Loss: 0.4080, Accuracy: 81.25%, Best_acc: 89.06%            \n",
      " 4981 / 4982\n",
      " Epoch 62, spent time:14.38s, valid: 76.84%\n",
      "Epoch [63/300], Step [120/127], Loss: 0.4579, Accuracy: 80.86%, Best_acc: 89.06%            \n",
      " 4981 / 4982\n",
      " Epoch 63, spent time:14.22s, valid: 76.66%\n",
      "Epoch [64/300], Step [120/127], Loss: 0.3885, Accuracy: 84.38%, Best_acc: 89.06%            \n",
      " 4981 / 4982\n",
      " Epoch 64, spent time:14.28s, valid: 77.02%\n",
      "Epoch [65/300], Step [120/127], Loss: 0.3531, Accuracy: 87.11%, Best_acc: 89.06%            \n",
      " 4981 / 4982\n",
      " Epoch 65, spent time:14.33s, valid: 77.44%\n",
      "Epoch [66/300], Step [120/127], Loss: 0.3811, Accuracy: 85.94%, Best_acc: 89.06%            \n",
      " 4981 / 4982\n",
      " Epoch 66, spent time:14.31s, valid: 77.46%\n",
      "Epoch [67/300], Step [40/127], Loss: 0.4200, Accuracy: 80.08%, Best_acc: 89.06%            "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c8622b961841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classify_model = classify_model.train()\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start = time.time()\n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        # Ramdomly get samples\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        embeds, targets = next(iter(data_loader))\n",
    "        \n",
    "        embeds = embeds.squeeze(1)\n",
    "        targets = targets.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        classify_model.zero_grad()\n",
    "        \n",
    "        outputs = classify_model(embeds)\n",
    "        \n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i_step%20 == 0:\n",
    "            # calculate the status\n",
    "            predict_result = outputs.argmax(1)\n",
    "            accuracy = torch.sum(predict_result == targets).item() / batch_size * 100\n",
    "            best_acc = accuracy if accuracy > best_acc else best_acc\n",
    "            \n",
    "            stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Accuracy: %.2f%%, Best_acc: %.2f%%\\\n",
    "            ' % (epoch, num_epochs, i_step, total_step, loss.item(), accuracy, best_acc)\n",
    "            print('\\r' + stats, end='')\n",
    "            sys.stdout.flush()\n",
    "    print('')        \n",
    "    valid_acc = valid_class_acc(classify_model, valid_data_loader)\n",
    "    print('\\n Epoch {}, spent time:{:.2f}s, valid: {:.2f}%'.format(epoch, time.time()-start, valid_acc))       \n",
    "    if epoch%1 == 0:\n",
    "        torch.save(classify_model.state_dict(), os.path.join('./models', 'class_multify_rm1layer_%d.pkl' % epoch))\n",
    "# torch.save(classify_model.state_dict(), os.path.join('./models', 'class_multify_rm1layer_last.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_data_loader = get_encoder_loader(transform_vaild, encoder, device, mode='valid', batch_size=batch_size)\n",
    "# valid_data_loader.dataset.save_to(\"./bottle_neck/resnet152_valid_rm1layer.h\")\n",
    "valid_data_loader = get_encoder_loader(transform_vaild, encoder, device, mode='valid', batch_size=batch_size, file=\"./bottle_neck/resnet152_valid_rm1layer.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_model.load_state_dict(torch.load('./models/class_multify_rm1layer_100.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy is 77.56%.\n"
     ]
    }
   ],
   "source": [
    "classify_model = classify_model.eval()\n",
    "predict = []\n",
    "for embed, _ in valid_data_loader.dataset:\n",
    "    p = classify_model(embed).argmax().item()\n",
    "    predict.append(p)\n",
    "    \n",
    "df_refer = valid_data_loader.dataset.refer\n",
    "df_refer[\"predict\"] = predict\n",
    "df_refer['correct'] = df_refer.predict == df_refer.disease_class\n",
    "accuracy = (df_refer.correct == True).sum()/len(df_refer)\n",
    "print('The final accuracy is %.2f%%.' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With 100 epoch the result is the best,yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./models/class_multify_rm1layer_100.pkl ./models/class_multify_rm1layer_good.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
